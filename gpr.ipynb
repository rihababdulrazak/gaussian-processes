{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import scipy as sp \n",
    "import numpy.random as rand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## This notebook is about Gaussian Process Regression (GPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### First define the regression problem and generate data\n",
    " ### Linear regression with parameters/weights $w$\n",
    " > ### $y_i = x_i^T w + \\epsilon$\n",
    " > ### where $\\epsilon$ is measurement noise $\\sim \\mathcal{N}(0, \\sigma_n^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of parameters: p=10..\n",
      "\n",
      "Length of data generated: N=100..\n",
      "\n",
      "Parameter (w) list: [0.5488135  0.71518937 0.60276338 0.54488318 0.4236548  0.64589411\n",
      " 0.43758721 0.891773   0.96366276 0.38344152]..\n",
      "\n",
      "Y is of size 100 times 1..\n",
      "\n",
      "X is of size 100 times 10..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# p parameters/weights\n",
    "p = 10\n",
    "w = np.zeros(p)\n",
    "rand.seed(0)  # set seed for parameters.\n",
    "for i in range(p):\n",
    "\tw[i] = rand.random()  # random values b/w 0 and 1.\n",
    "\n",
    "# generate data\n",
    "N = 100  # no.of data points\n",
    "\n",
    "# noise\n",
    "rand.seed(2)  # set seed for noise.\n",
    "v = rand.normal(loc=0.0, scale=1.0, size=(N,)) \n",
    "\n",
    "X = np.zeros([N,p])\n",
    "for i in range(p):\n",
    "\trand.seed(i+10)  # set seed for i-th data.\n",
    "\tX[:,i] = rand.normal(rand.randint(5,15), scale=2.0, size=N)\n",
    "\n",
    "Yt = np.dot(X, w)  # compute outputs\n",
    "Y = Yt + v  # noisy outputs\n",
    "\n",
    "print(\"No.of parameters: p=%d..\\n\" %(p))\n",
    "print(\"Length of data generated: N=%d..\\n\" %(N))\n",
    "print(\"Parameter (w) list: %s..\\n\" %(str(w)))\n",
    "print(\"Y is of size %d times 1..\\n\" %(N))\n",
    "print(\"X is of size %d times %d..\\n\" %(N,p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Use GPR to estimate parameters $w$ from data $(X,Y)$\n",
    " > ### $y_i = x_i^T w + \\epsilon$\n",
    " > ### where $\\epsilon$ is measurement noise $\\sim \\mathcal{N}(0, \\sigma_n^2)$.\n",
    "\n",
    " ### In terms of the data matrices,\n",
    " > ### $Y = X \\cdot w + e$\n",
    " > ### Given $X$ and $w$, the probability distribution of $Y$ (likelihood function) can be obtained as\n",
    " >> ### $p(Y|X,w) \\sim \\mathcal{N}(X \\cdot w, \\sigma_n^2 \\cdot I)$.\n",
    "\n",
    " ### Also we can assume some prior distribution for the parameters $w$ which reflects available information on the parameters (in case no prior information is available, we may set them to be zero-mean with large variance),\n",
    " > ### $p(w) \\sim \\mathcal{N}(0,\\Sigma_p)$\n",
    "\n",
    " ### We can use Bayes theorem to compute the posterior probability distribution given the prior and the likelihood,\n",
    " > ### $\\mbox{posterior} = \\frac{\\mbox{likelihood} \\times \\mbox{prior}}{\\mbox{marginal likelihood}} $\n",
    " > ### or,\n",
    " > ### $p(w|Y,X) = \\frac{p(Y|X,w) \\cdot p(w)}{p(Y|X)}$\n",
    " > ### The denominator is independent of $w$ and acts like a normalization factor.\n",
    " > ### Using the Bayes formula, the posterior can be computed to be proporational to\n",
    " > ### $p(w|X,Y) \\propto \\exp \\left\\{ -\\frac{1}{2}(w-\\bar{w})^T \\left( \\frac{1}{\\sigma_n^2} X^T X + \\Sigma_p^{-1} \\right) (w-\\bar{w}) \\right\\} $,\n",
    " > ### or,\n",
    " > ### $p(w|X,Y) \\sim \\mathcal{N}(\\bar{w}, A^{-1})$,\n",
    " > ### where $A = \\left( \\frac{1}{\\sigma_n^2} X^T X + \\Sigma_p^{-1} \\right)$, $\\bar{w} = \\frac{1}{\\sigma_n^2} A^{-1} X^T Y$.\n",
    "\n",
    " ### Estimate of the weight vector can be taken as $\\bar{w}$ and the variance (uncertainty) associated with it given by $A^{-1}$.\n",
    "\n",
    " ### Prediction (at point $x_*$):\n",
    " > ### $p(f(x_*)|X,Y) \\sim \\mathcal{N}(x_*^T \\bar{w}, x_*^T A^{-1} x_*)$\n",
    "\n",
    " ### Estimate of the value at a test point $x_*$ can be taken as $x_*^T \\bar{w}$ and the variance (uncertainty) associated with it given by $x_*^T A^{-1} x_*$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Get the posterior distribution of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the parameters\n",
    "sigma_n = 1.5  # output noise variance, original value = 1\n",
    "Sigma_p = 10*np.eye(p)  # prior variance\n",
    "Sigma_p_inv = np.linalg.inv(Sigma_p)\n",
    "\n",
    "A = (1/sigma_n*sigma_n)*np.dot(X.transpose(), X) + Sigma_p_inv\n",
    "A_inv = np.linalg.inv(A)\n",
    "\n",
    "wbar = (1/sigma_n*sigma_n)*np.dot(A_inv, np.dot(X.transpose(), Y))\n",
    "\n",
    "# also compute the least squares value for comparison\n",
    "w_ls = np.linalg.inv(np.dot(X.transpose(), X))\n",
    "w_ls = np.dot(w_ls, np.dot(X.transpose(),Y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Predict the value at a test point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test point (xs): [12.44545943  7.76531819  7.53822079 13.61685461  9.31865966  7.62370073\n",
      "  5.51214869 13.52793817 13.73512622 17.81593541]..\n",
      "\n",
      "Value y=f(xs) obtained using GPR: (66.30, 1.11)..\n",
      "\n",
      "Value y=f(xs) obtained using LS: 66.30..\n",
      "\n",
      "Value y=f(xs) true: 67.76..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xs = np.zeros(p)\n",
    "for i in range(p):\n",
    "\txs[i] = rand.normal(rand.randint(5,15), scale=2.0)\n",
    "\n",
    "fxs = np.dot(xs, wbar)\n",
    "sigma_fxs = np.dot(xs, np.dot(A_inv, xs))\n",
    "\n",
    "fxs_ls = np.dot(xs, w_ls)\n",
    "fxs_true = np.dot(xs, w)\n",
    "\n",
    "print(\"Test point (xs): %s..\\n\" %(str(xs)))\n",
    "print(\"Value y=f(xs) obtained using GPR: (%.2f, %.2f)..\\n\" %(fxs, sigma_fxs))\n",
    "print(\"Value y=f(xs) obtained using LS: %.2f..\\n\" %(fxs_ls))\n",
    "print(\"Value y=f(xs) true: %.2f..\\n\" %(fxs_true))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### This can be extended in a straight-forward way to the case the features are nonlinear,\n",
    " > ### $y_i = \\phi(x_i)^T w + \\epsilon$.\n",
    "\n",
    " ### In terms of data matrices,\n",
    " > ### $Y = \\Phi(X)^T w + e$.\n",
    "\n",
    " ### In this case,\n",
    " > ### $p(f(x_*)|X,Y) \\sim \\mathcal{N}(\\phi(x_*)^T \\bar{w}, \\phi(x_*)^T A^{-1} \\phi(x_*))$\n",
    " > ### where $A = \\left( \\frac{1}{\\sigma_n^2} \\Phi(X)^T \\Phi(X) + \\Sigma_p^{-1} \\right)$, $\\bar{w} = \\frac{1}{\\sigma_n^2} A^{-1} \\Phi(X)^T Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
